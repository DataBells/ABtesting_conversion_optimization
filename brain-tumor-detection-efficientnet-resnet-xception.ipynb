{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de50bed",
   "metadata": {
    "papermill": {
     "duration": 0.015947,
     "end_time": "2024-05-05T20:07:52.876455",
     "exception": false,
     "start_time": "2024-05-05T20:07:52.860508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;\">Brain Tumor Detection using<br>EfficientNetB0, ResNet101, and Xception</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed19cc15",
   "metadata": {
    "papermill": {
     "duration": 0.015229,
     "end_time": "2024-05-05T20:07:52.907268",
     "exception": false,
     "start_time": "2024-05-05T20:07:52.892039",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <p style=\"background-color:#003166;font-family:newtimeroman;font-size:150%;text-align:center;border-radius:50px 10px;\">Introduction</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc26f71",
   "metadata": {
    "papermill": {
     "duration": 0.015107,
     "end_time": "2024-05-05T20:07:52.937747",
     "exception": false,
     "start_time": "2024-05-05T20:07:52.922640",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In my previous exploration of the Brain Tumor dataset ([Brain Tumor Detection using Tensorflow CNN](https://www.kaggle.com/code/anitarostami/brain-tumor-detection-using-tensorflow-cnn#notebook-container)), I delved into Image Classification using CNNs and compared augmented and unaugmented models. While both approaches provided insights, the unaugmented model shown potential for balancing accuracy and computational efficiency . However, due to the dataset's size limits, reaching ideal accuracy remained difficult. In this new notebook, I switch to Transfer Learning and use pre-trained models like EfficientNetB0, ResNet101, and Xception to significantly enhance classification accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c76982",
   "metadata": {
    "papermill": {
     "duration": 0.015079,
     "end_time": "2024-05-05T20:07:52.968797",
     "exception": false,
     "start_time": "2024-05-05T20:07:52.953718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> I hope you found value and insights in this notebook. If you have any suggestions or thoughts, please feel free to share them. If you enjoyed the content, consider giving it an upvote. Thank you! </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96d3747",
   "metadata": {
    "papermill": {
     "duration": 0.01517,
     "end_time": "2024-05-05T20:07:52.999603",
     "exception": false,
     "start_time": "2024-05-05T20:07:52.984433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "   <a id='top'></a>\n",
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<p style=\"background-color:#003166;font-family:newtimeroman;font-size:150%;text-align:center;border-radius:50px 10px;\">TABLE OF CONTENTS</p>   \n",
    "    \n",
    "* [1. IMPORTING LIBRARIES](#1)\n",
    "    \n",
    "* [2. DATA PREPRATION](#2)\n",
    "    \n",
    "* [2. TRANSFER LEARNING](#3)\n",
    "    \n",
    "* [3. EfficientNetB0](#4)\n",
    "    \n",
    "* [4. ResNet101](#5)   \n",
    "      \n",
    "* [6. Xception](#6)\n",
    "    \n",
    "* [7. CONCLUSION](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3871463",
   "metadata": {
    "papermill": {
     "duration": 0.015055,
     "end_time": "2024-05-05T20:07:53.030161",
     "exception": false,
     "start_time": "2024-05-05T20:07:53.015106",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"1\"></a>\n",
    "# <p style=\"background-color:#003166;font-family:newtimeroman;font-size:150%;text-align:center;border-radius:50px 10px;\">Importing Libraries</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bf3ce44",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 14.05937,
     "end_time": "2024-05-05T20:08:07.104863",
     "exception": false,
     "start_time": "2024-05-05T20:07:53.045493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "Requirement already satisfied: mplcyberpunk in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.7.5)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mplcyberpunk) (3.9.4)\n",
      "Requirement already satisfied: numpy>1.24.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mplcyberpunk) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib->mplcyberpunk) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib->mplcyberpunk) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib->mplcyberpunk) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib->mplcyberpunk) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib->mplcyberpunk) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib->mplcyberpunk) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib->mplcyberpunk) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib->mplcyberpunk) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib->mplcyberpunk) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mplcyberpunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ac1915",
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 14.927885,
     "end_time": "2024-05-05T20:08:22.049101",
     "exception": false,
     "start_time": "2024-05-05T20:08:07.121216",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmplcyberpunk\u001b[39;00m\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcyberpunk\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m shuffle\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import mplcyberpunk\n",
    "plt.style.use(\"cyberpunk\")\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D,GlobalAveragePooling2D, Dropout, Dense, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "from warnings import filterwarnings\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9917ece",
   "metadata": {
    "papermill": {
     "duration": 0.020019,
     "end_time": "2024-05-05T20:08:22.095476",
     "exception": false,
     "start_time": "2024-05-05T20:08:22.075457",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"2\"></a>\n",
    "# <p style=\"background-color:#003166;font-family:newtimeroman;font-size:150%;text-align:center;border-radius:50px 10px;\">Data Preperation</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01201f88",
   "metadata": {
    "papermill": {
     "duration": 24.176737,
     "end_time": "2024-05-05T20:08:46.294583",
     "exception": false,
     "start_time": "2024-05-05T20:08:22.117846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "labels = ['glioma_tumor','no_tumor','meningioma_tumor','pituitary_tumor']\n",
    "\n",
    "\n",
    "image_size = 150\n",
    "for i in labels:\n",
    "    folderPath = os.path.join('../input/Training',i)\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        img = cv2.imread(os.path.join(folderPath,j))\n",
    "        img = cv2.resize(img,(image_size, image_size))\n",
    "        X_train.append(img)\n",
    "        y_train.append(i)\n",
    "        \n",
    "for i in labels:\n",
    "    folderPath = os.path.join('../input/Testing',i)\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        img = cv2.imread(os.path.join(folderPath,j))\n",
    "        img = cv2.resize(img,(image_size,image_size))\n",
    "        X_train.append(img)\n",
    "        y_train.append(i)\n",
    "        \n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21b57c1",
   "metadata": {
    "papermill": {
     "duration": 0.039681,
     "end_time": "2024-05-05T20:08:46.373391",
     "exception": false,
     "start_time": "2024-05-05T20:08:46.333710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b75b91",
   "metadata": {
    "papermill": {
     "duration": 0.595065,
     "end_time": "2024-05-05T20:08:47.007467",
     "exception": false,
     "start_time": "2024-05-05T20:08:46.412402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the bar plot for each label\n",
    "label_counts = {label: np.sum(y_train == label) for label in labels}\n",
    "\n",
    "# Plot the bar plot and sample images in one chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "colors = [\"C0\", \"C1\", \"C2\", \"C3\"]\n",
    "\n",
    "# Plot the histogram\n",
    "plt.subplot(2, 1, 1)\n",
    "bars = plt.bar(label_counts.keys(), label_counts.values(), color=colors)\n",
    "mplcyberpunk.add_bar_gradient(bars=bars)\n",
    "# plt.xlabel('Labels')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Labels')\n",
    "\n",
    "# Plot sample images from each label\n",
    "k = 0\n",
    "for i in labels:\n",
    "    j = 0\n",
    "    while True:\n",
    "        if y_train[j] == i:\n",
    "            plt.subplot(2, 4, k + 5) \n",
    "            plt.imshow(X_train[j])\n",
    "            plt.axis('off')\n",
    "            k += 1\n",
    "            break\n",
    "        j += 1\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4750b1",
   "metadata": {
    "papermill": {
     "duration": 0.04049,
     "end_time": "2024-05-05T20:08:47.088464",
     "exception": false,
     "start_time": "2024-05-05T20:08:47.047974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataset Split: Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac271b6d",
   "metadata": {
    "papermill": {
     "duration": 0.115502,
     "end_time": "2024-05-05T20:08:47.244391",
     "exception": false,
     "start_time": "2024-05-05T20:08:47.128889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train,y_train, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1caee5",
   "metadata": {
    "papermill": {
     "duration": 0.112359,
     "end_time": "2024-05-05T20:08:47.397463",
     "exception": false,
     "start_time": "2024-05-05T20:08:47.285104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X_train,y_train, test_size=0.1,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665cf0be",
   "metadata": {
    "papermill": {
     "duration": 0.091809,
     "end_time": "2024-05-05T20:08:47.530564",
     "exception": false,
     "start_time": "2024-05-05T20:08:47.438755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### One-Hot Encoding Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cfd87f",
   "metadata": {
    "papermill": {
     "duration": 0.052833,
     "end_time": "2024-05-05T20:08:47.625186",
     "exception": false,
     "start_time": "2024-05-05T20:08:47.572353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train_new = []\n",
    "for i in y_train:\n",
    "    y_train_new.append(labels.index(i))\n",
    "y_train = y_train_new\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "\n",
    "y_test_new = []\n",
    "for i in y_test:\n",
    "    y_test_new.append(labels.index(i))\n",
    "y_test = y_test_new\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481a2cb9",
   "metadata": {
    "papermill": {
     "duration": 0.040398,
     "end_time": "2024-05-05T20:08:47.707832",
     "exception": false,
     "start_time": "2024-05-05T20:08:47.667434",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"3\"></a>\n",
    "# <p style=\"background-color:#003166;font-family:newtimeroman;font-size:150%;text-align:center;border-radius:50px 10px;\">Transfer Learning</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcefb849",
   "metadata": {
    "papermill": {
     "duration": 0.04173,
     "end_time": "2024-05-05T20:08:47.790086",
     "exception": false,
     "start_time": "2024-05-05T20:08:47.748356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Transfer learning uses knowledge learned from training on one task to improve learning on another, which is especially beneficial when data is limited. The model can learn more quickly and avoid overfitting by using learned features from a related task. It works by starting with a pre-trained model's base layers, identifying transfer layers capturing relevant information, and fine-tuning these layers with new task data to adapt the model efficiently. This method is particularly useful in deep learning for tasks involving image recognition and classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b17817",
   "metadata": {
    "papermill": {
     "duration": 0.040719,
     "end_time": "2024-05-05T20:08:47.871768",
     "exception": false,
     "start_time": "2024-05-05T20:08:47.831049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Fundamental Components and Techniques in Neural Network Training**\n",
    "\n",
    "1. Dense: A fully connected layer that learns complicated patterns in data by connecting all neurons in the previous and subsequent layers.\n",
    "\n",
    "2. GlobalAveragePooling2D: A pooling layer that determines the average value of each feature map across spatial dimensions, lowering spatial dimensions and keeping crucial information.\n",
    "\n",
    "3. Dropout: a regularization technique that randomly sets a fraction of input units to zero during training, preventing overfitting and requiring the model to learn resilient features.\n",
    "\n",
    "4. BatchNormalization: This technique normalizes each layer's activations to stabilize training and reduce internal covariate shift, resulting in faster convergence and improved generalization.\n",
    "\n",
    "5. Callbacks: Callbacks are TensorFlow/Keras functions that can do specific actions during training, such as storing the model, adjusting learning rates, or halting training based on conditions.\n",
    "\n",
    "6. Early Stopping: A callback technique that halts training when a monitored metric stops improving, preventing overfitting and conserving computational resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b75074c",
   "metadata": {
    "papermill": {
     "duration": 0.040213,
     "end_time": "2024-05-05T20:08:47.952718",
     "exception": false,
     "start_time": "2024-05-05T20:08:47.912505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"4\"></a>\n",
    "# <p style=\"background-color:#003166;font-family:newtimeroman;font-size:150%;text-align:center;border-radius:50px 10px;\">EfficientNet</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dcc777",
   "metadata": {
    "papermill": {
     "duration": 0.041203,
     "end_time": "2024-05-05T20:08:48.033962",
     "exception": false,
     "start_time": "2024-05-05T20:08:47.992759",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* EfficientNet-b0, trained on the huge ImageNet dataset, has learned how to classify images in 1000 different object categories, ranging from ordinary items like keyboards and pencils to numerous animals. Furthermore, EfficientNet models are notable for their efficient architecture, which achieves high accuracy with less parameters than traditional models such as ResNet-101.\n",
    "\n",
    "* EfficientNet uses a compound scaling approach to consistently scale depth, width, and resolution. Its stem, the first processing layer, consists of a 3x3 Conv2D with stride 2, Batch Normalization, and Swish activation. The Conv2D layer is essential, detecting features and forming complex patterns crucial for CNNs in image recognition tasks. Filters of size 3x3 traverse the input, capturing spatial hierarchies such as edges and textures, while a stride of 2 downsamples, reducing computational load and aiding feature extraction in subsequent layers. This layer's role in the feature hierarchy comprises low-level feature extraction, which contributes to the recognition of complicated features deeper in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fc3973",
   "metadata": {
    "papermill": {
     "duration": 3.687875,
     "end_time": "2024-05-05T20:08:51.762135",
     "exception": false,
     "start_time": "2024-05-05T20:08:48.074260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the EfficientNetB0 model pretrained on ImageNet without the top layers\n",
    "efficientnetB0 = tf.keras.applications.EfficientNetB0(weights='imagenet',\n",
    "                                                      include_top=False,\n",
    "                                                      input_shape=(image_size, image_size, 3))\n",
    "\n",
    "\n",
    "# Build the custom model on top of the EfficientNetB0 base\n",
    "model = efficientnetB0.output\n",
    "model = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
    "model = tf.keras.layers.Dense(1024,activation='relu')(model)\n",
    "model = tf.keras.layers.Dropout(rate=0.4)(model)\n",
    "model = tf.keras.layers.Dense(4,activation='softmax')(model)\n",
    "model = tf.keras.models.Model(inputs=efficientnetB0.input, outputs = model)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e51980",
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.372895,
     "end_time": "2024-05-05T20:08:52.178602",
     "exception": false,
     "start_time": "2024-05-05T20:08:51.805707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bdaeac",
   "metadata": {
    "papermill": {
     "duration": 0.055913,
     "end_time": "2024-05-05T20:08:52.281417",
     "exception": false,
     "start_time": "2024-05-05T20:08:52.225504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tensorboard callback for logging training metrics\n",
    "tensorboard = TensorBoard(log_dir='logs')\n",
    "\n",
    "# Modelcheckpoint callback to save the best model \n",
    "checkpoint = ModelCheckpoint(\"efficientnetB0.keras\", monitor=\"val_accuracy\",\n",
    "                             save_best_only=True, verbose=1)\n",
    "\n",
    "# ReduceLROnPlateau callback to reduce learning rate if validation accuracy plateaus\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=2, \n",
    "                              min_delta=0.0001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c08289e",
   "metadata": {
    "papermill": {
     "duration": 254.138062,
     "end_time": "2024-05-05T20:13:06.466782",
     "exception": false,
     "start_time": "2024-05-05T20:08:52.328720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train,validation_split = 0.1, epochs = 12, verbose = 1,\n",
    "                    batch_size = 32, callbacks=[tensorboard,checkpoint,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18513dc3",
   "metadata": {
    "papermill": {
     "duration": 0.767838,
     "end_time": "2024-05-05T20:13:07.380282",
     "exception": false,
     "start_time": "2024-05-05T20:13:06.612444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting training and validation loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "mplcyberpunk.make_lines_glow()\n",
    "\n",
    "# Plotting training and validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "mplcyberpunk.make_lines_glow()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0763cf80",
   "metadata": {
    "papermill": {
     "duration": 0.132326,
     "end_time": "2024-05-05T20:13:07.649645",
     "exception": false,
     "start_time": "2024-05-05T20:13:07.517319",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <p style=\"background-color:#003166;font-family:newtimeroman;font-size:150%;text-align:center;border-radius:50px 10px;\">Evaluation</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a4771",
   "metadata": {
    "papermill": {
     "duration": 14.468915,
     "end_time": "2024-05-05T20:13:22.249891",
     "exception": false,
     "start_time": "2024-05-05T20:13:07.780976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_true_test = np.argmax(y_test, axis=1)\n",
    "y_pred_test = np.argmax(model.predict(X_test), axis=1) \n",
    "\n",
    "heatmap = sns.heatmap(confusion_matrix(y_true_test,y_pred_test), annot=True, fmt='d', cmap='Blues_r',\n",
    "                      xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84a04dc",
   "metadata": {
    "papermill": {
     "duration": 0.15104,
     "end_time": "2024-05-05T20:13:22.533898",
     "exception": false,
     "start_time": "2024-05-05T20:13:22.382858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f88af24",
   "metadata": {
    "papermill": {
     "duration": 0.132615,
     "end_time": "2024-05-05T20:13:22.798735",
     "exception": false,
     "start_time": "2024-05-05T20:13:22.666120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <p style=\"background-color:#003166;font-family:newtimeroman;font-size:150%;text-align:center;border-radius:50px 10px;\">Prediction</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbd4853",
   "metadata": {
    "papermill": {
     "duration": 5.319696,
     "end_time": "2024-05-05T20:13:28.249245",
     "exception": false,
     "start_time": "2024-05-05T20:13:22.929549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_index = np.random.randint(0, len(X_test))\n",
    "random_img = X_test[random_index]  \n",
    "predictions = model.predict(random_img.reshape(1, 150, 150, 3))  # Reshape and preprocess the image\n",
    "\n",
    "# Interpret the model's predictions\n",
    "predicted_class = np.argmax(predictions)  # Get the index of the class with the highest probability\n",
    "predicted_label = labels[predicted_class]  # Convert class to label\n",
    "confidence = predictions[0][predicted_class]\n",
    "\n",
    "actual_index = y_test[random_index]  # Get the one-hot encoded actual class\n",
    "actual_class = np.argmax(actual_index)  \n",
    "actual_label = labels[actual_class]  \n",
    "\n",
    "# Display the image and prediction information\n",
    "print(f\"\\033[94mPredicted label: {predicted_label}\\033[0m \\n\\033[92mActual label: {actual_label}\\033[0m \\n\\033[93mConfidence: {confidence*100:.2f}%\\033[0m\\n\")\n",
    "plt.figure(figsize = (3,3))\n",
    "plt.imshow(random_img)\n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aca7d08",
   "metadata": {
    "papermill": {
     "duration": 0.150326,
     "end_time": "2024-05-05T20:13:28.576682",
     "exception": false,
     "start_time": "2024-05-05T20:13:28.426356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"5\"></a>\n",
    "# <p style=\"background-color:#003166;font-family:newtimeroman;font-size:150%;text-align:center;border-radius:50px 10px;\">ResNet101</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5277e8",
   "metadata": {
    "papermill": {
     "duration": 0.133436,
     "end_time": "2024-05-05T20:13:28.844186",
     "exception": false,
     "start_time": "2024-05-05T20:13:28.710750",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ResNet-101, a 101-layer deep convolutional neural network, offers a pretrained version trained on over a million images from the ImageNet database. It excels in classifying images over 1000 object categories, demonstrating its adaptability in recognizing different objects and animals. ResNet-101, with an image input size of 224-by-224, uses extensive feature representations, making it a strong choice for a variety of image classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c3b600",
   "metadata": {
    "papermill": {
     "duration": 9.746984,
     "end_time": "2024-05-05T20:13:38.724805",
     "exception": false,
     "start_time": "2024-05-05T20:13:28.977821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the ResNet101 model pretrained on ImageNet without the top layers\n",
    "resnet = tf.keras.applications.ResNet101(weights='imagenet', include_top=False,\n",
    "                                         input_shape=(image_size, image_size, 3))\n",
    "\n",
    "# Build the custom model on top of the ResNet101 base\n",
    "\n",
    "model = resnet.output\n",
    "model = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
    "model = tf.keras.layers.Dropout(rate=0.5)(model)\n",
    "model = tf.keras.layers.Dense(4,activation='softmax')(model)\n",
    "model = tf.keras.models.Model(inputs=resnet.input, outputs = model)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282ce22d",
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 1.261495,
     "end_time": "2024-05-05T20:13:40.127830",
     "exception": false,
     "start_time": "2024-05-05T20:13:38.866335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b1a820",
   "metadata": {
    "papermill": {
     "duration": 0.160449,
     "end_time": "2024-05-05T20:13:40.438407",
     "exception": false,
     "start_time": "2024-05-05T20:13:40.277958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tensorboard callback for logging training metrics\n",
    "tensorboard = TensorBoard(log_dir='logs')\n",
    "\n",
    "# Modelcheckpoint callback to save the best model \n",
    "checkpoint = ModelCheckpoint(\"efficientnetB0.keras\", monitor=\"val_accuracy\",\n",
    "                             save_best_only=True, verbose=1)\n",
    "\n",
    "# ReduceLROnPlateau callback to reduce learning rate if validation accuracy plateaus\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=2, \n",
    "                              min_delta=0.0001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3aef23",
   "metadata": {
    "papermill": {
     "duration": 449.276364,
     "end_time": "2024-05-05T20:21:09.862398",
     "exception": false,
     "start_time": "2024-05-05T20:13:40.586034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train,validation_split=0.1, epochs =15, verbose=1, batch_size=32,\n",
    "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3953ca",
   "metadata": {
    "papermill": {
     "duration": 1.028143,
     "end_time": "2024-05-05T20:21:11.145056",
     "exception": false,
     "start_time": "2024-05-05T20:21:10.116913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting training and validation loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "mplcyberpunk.make_lines_glow()\n",
    "\n",
    "# Plotting training and validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "mplcyberpunk.make_lines_glow()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295646a7",
   "metadata": {
    "papermill": {
     "duration": 0.260947,
     "end_time": "2024-05-05T20:21:11.673082",
     "exception": false,
     "start_time": "2024-05-05T20:21:11.412135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <p style=\"background-color:#003166;font-family:newtimeroman;font-size:150%;text-align:center;border-radius:50px 10px;\">Evaluation</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b522f6f",
   "metadata": {
    "papermill": {
     "duration": 18.62713,
     "end_time": "2024-05-05T20:21:30.558849",
     "exception": false,
     "start_time": "2024-05-05T20:21:11.931719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_true_test = np.argmax(y_test, axis=1)\n",
    "y_pred_test = np.argmax(model.predict(X_test), axis=1) \n",
    "\n",
    "heatmap = sns.heatmap(confusion_matrix(y_true_test,y_pred_test), annot=True, fmt='d', cmap='Blues_r',\n",
    "                      xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b101cc",
   "metadata": {
    "papermill": {
     "duration": 0.331816,
     "end_time": "2024-05-05T20:21:31.153597",
     "exception": false,
     "start_time": "2024-05-05T20:21:30.821781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55994915",
   "metadata": {
    "papermill": {
     "duration": 0.267272,
     "end_time": "2024-05-05T20:21:31.695819",
     "exception": false,
     "start_time": "2024-05-05T20:21:31.428547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <p style=\"background-color:#003166;font-family:newtimeroman;font-size:150%;text-align:center;border-radius:50px 10px;\">Prediction</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d898d39",
   "metadata": {
    "papermill": {
     "duration": 4.93849,
     "end_time": "2024-05-05T20:21:36.908527",
     "exception": false,
     "start_time": "2024-05-05T20:21:31.970037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_index = np.random.randint(0, len(X_test))\n",
    "random_img = X_test[random_index]  \n",
    "predictions = model.predict(random_img.reshape(1, 150, 150, 3))  # Reshape and preprocess the image\n",
    "\n",
    "# Interpret the model's predictions\n",
    "predicted_class = np.argmax(predictions)  # Get the index of the class with the highest probability\n",
    "predicted_label = labels[predicted_class]  # Convert class to label\n",
    "confidence = predictions[0][predicted_class]\n",
    "\n",
    "actual_index = y_test[random_index]  # Get the one-hot encoded actual class\n",
    "actual_class = np.argmax(actual_index)  \n",
    "actual_label = labels[actual_class]  \n",
    "\n",
    "# Display the image and prediction information\n",
    "print(f\"\\033[94mPredicted label: {predicted_label}\\033[0m \\n\\033[92mActual label: {actual_label}\\033[0m \\n\\033[93mConfidence: {confidence*100:.2f}%\\033[0m\\n\")\n",
    "plt.figure(figsize = (3,3))\n",
    "plt.imshow(random_img)\n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0681141d",
   "metadata": {
    "papermill": {
     "duration": 0.275462,
     "end_time": "2024-05-05T20:21:37.499239",
     "exception": false,
     "start_time": "2024-05-05T20:21:37.223777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"6\"></a>\n",
    "# <p style=\"background-color:#003166;font-family:newtimeroman;font-size:150%;text-align:center;border-radius:50px 10px;\">Xception</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6b89e4",
   "metadata": {
    "papermill": {
     "duration": 0.266218,
     "end_time": "2024-05-05T20:21:38.033391",
     "exception": false,
     "start_time": "2024-05-05T20:21:37.767173",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Xception, a revolutionary CNN architecture, incorporates depthwise separable convolutions, which reduces parameters and computational cost while maintaining efficacy. It uses separable convolutional blocks, an entry-exit flow structure, and skip connections similar to ResNet to provide efficient training and hierarchical feature learning. Key approaches include global depthwise convolutions for context understanding, data augmentation, batch normalization for stability, and transfer learning potential from ImageNet. With 71 layers, pretrained Xception performs at ImageNet classification, demonstrating its efficiency and adaptability in deep learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e77be2a",
   "metadata": {
    "papermill": {
     "duration": 5.034452,
     "end_time": "2024-05-05T20:21:43.341303",
     "exception": false,
     "start_time": "2024-05-05T20:21:38.306851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the Xception model pretrained on ImageNet without the top layers\n",
    "xception = tf.keras.applications.Xception(weights='imagenet', include_top=False,\n",
    "                                          input_shape=(image_size, image_size, 3))\n",
    "\n",
    "# Build the custom model on top of the Xception base\n",
    "model = xception.output\n",
    "model = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
    "model = tf.keras.layers.Dense(1536,activation='relu')(model)\n",
    "model = tf.keras.layers.Dropout(rate=0.5)(model)\n",
    "model = tf.keras.layers.Dense(4,activation='softmax')(model)\n",
    "model = tf.keras.models.Model(inputs=xception.input, outputs = model)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9532f975",
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.462084,
     "end_time": "2024-05-05T20:21:44.129947",
     "exception": false,
     "start_time": "2024-05-05T20:21:43.667863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c1b1b2",
   "metadata": {
    "papermill": {
     "duration": 0.278271,
     "end_time": "2024-05-05T20:21:44.695214",
     "exception": false,
     "start_time": "2024-05-05T20:21:44.416943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tensorboard callback for logging training metrics\n",
    "tensorboard = TensorBoard(log_dir='logs')\n",
    "\n",
    "# Modelcheckpoint callback to save the best model \n",
    "checkpoint = ModelCheckpoint(\"efficientnetB0.keras\", monitor=\"val_accuracy\",\n",
    "                             save_best_only=True, verbose=1)\n",
    "\n",
    "# ReduceLROnPlateau callback to reduce learning rate if validation accuracy plateaus\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=2, \n",
    "                              min_delta=0.0001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2eb270",
   "metadata": {
    "papermill": {
     "duration": 246.230239,
     "end_time": "2024-05-05T20:25:51.199732",
     "exception": false,
     "start_time": "2024-05-05T20:21:44.969493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train,validation_split=0.1, epochs =12, verbose=1, batch_size=32,\n",
    "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a007d3",
   "metadata": {
    "papermill": {
     "duration": 1.102147,
     "end_time": "2024-05-05T20:25:52.660162",
     "exception": false,
     "start_time": "2024-05-05T20:25:51.558015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting training and validation loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "mplcyberpunk.make_lines_glow()\n",
    "\n",
    "# Plotting training and validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "mplcyberpunk.make_lines_glow()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6640114",
   "metadata": {
    "papermill": {
     "duration": 0.410981,
     "end_time": "2024-05-05T20:25:53.431879",
     "exception": false,
     "start_time": "2024-05-05T20:25:53.020898",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <p style=\"background-color:#003166;font-family:newtimeroman;font-size:150%;text-align:center;border-radius:50px 10px;\">Evaluation</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e882dc",
   "metadata": {
    "papermill": {
     "duration": 8.2695,
     "end_time": "2024-05-05T20:26:02.061179",
     "exception": false,
     "start_time": "2024-05-05T20:25:53.791679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_true_test = np.argmax(y_test, axis=1)\n",
    "y_pred_test = np.argmax(model.predict(X_test), axis=1) \n",
    "\n",
    "heatmap = sns.heatmap(confusion_matrix(y_true_test,y_pred_test), annot=True, fmt='d', cmap='Blues_r',\n",
    "                      xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4040916",
   "metadata": {
    "papermill": {
     "duration": 0.370051,
     "end_time": "2024-05-05T20:26:02.784612",
     "exception": false,
     "start_time": "2024-05-05T20:26:02.414561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed125a8",
   "metadata": {
    "papermill": {
     "duration": 0.35476,
     "end_time": "2024-05-05T20:26:03.490431",
     "exception": false,
     "start_time": "2024-05-05T20:26:03.135671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <p style=\"background-color:#003166;font-family:newtimeroman;font-size:150%;text-align:center;border-radius:50px 10px;\">Prediction</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9060d57",
   "metadata": {
    "papermill": {
     "duration": 3.716896,
     "end_time": "2024-05-05T20:26:07.616658",
     "exception": false,
     "start_time": "2024-05-05T20:26:03.899762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_index = np.random.randint(0, len(X_test))\n",
    "random_img = X_test[random_index]  \n",
    "predictions = model.predict(random_img.reshape(1, 150, 150, 3))  # Reshape and preprocess the image\n",
    "\n",
    "# Interpret the model's predictions\n",
    "predicted_class = np.argmax(predictions)  # Get the index of the class with the highest probability\n",
    "predicted_label = labels[predicted_class]  # Convert class to label\n",
    "confidence = predictions[0][predicted_class]\n",
    "\n",
    "actual_index = y_test[random_index]  # Get the one-hot encoded actual class\n",
    "actual_class = np.argmax(actual_index)  \n",
    "actual_label = labels[actual_class] \n",
    "\n",
    "# Display the image and prediction information\n",
    "print(f\"\\033[94mPredicted label: {predicted_label}\\033[0m \\n\\033[92mActual label: {actual_label}\\033[0m \\n\\033[93mConfidence: {confidence*100:.2f}%\\033[0m\\n\")\n",
    "plt.figure(figsize = (3,3))\n",
    "plt.imshow(random_img)\n",
    "plt.axis('off')  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901494ff",
   "metadata": {
    "papermill": {
     "duration": 0.363749,
     "end_time": "2024-05-05T20:26:08.397167",
     "exception": false,
     "start_time": "2024-05-05T20:26:08.033418",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"7\"></a>\n",
    "# <p style=\"background-color:#003166;font-family:newtimeroman;font-size:150%;text-align:center;border-radius:50px 10px;\">Conclusion</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbd4f36",
   "metadata": {
    "papermill": {
     "duration": 0.381842,
     "end_time": "2024-05-05T20:26:09.172644",
     "exception": false,
     "start_time": "2024-05-05T20:26:08.790802",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Through the exploration of Transfer Learning models, including EfficientNet-b0, ResNet101, VGG 19, and Xception, this notebook has showcased the power of leveraging pre-existing knowledge to enhance classification accuracy. These models offer a robust framework for tackling the challenges posed by small datasets, exhibiting improved performance and paving the way for more accurate brain tumor detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64015895",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:08:37.870892Z",
     "iopub.status.busy": "2024-05-05T19:08:37.870147Z",
     "iopub.status.idle": "2024-05-05T19:08:37.883288Z",
     "shell.execute_reply": "2024-05-05T19:08:37.882110Z",
     "shell.execute_reply.started": "2024-05-05T19:08:37.870847Z"
    },
    "papermill": {
     "duration": 0.373285,
     "end_time": "2024-05-05T20:26:09.909832",
     "exception": false,
     "start_time": "2024-05-05T20:26:09.536547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <p><center style=\"color:#003166;font-family:newtimeroman;;\">Thank You!</center></p>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 672377,
     "sourceId": 1183165,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1103.458722,
   "end_time": "2024-05-05T20:26:13.453789",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-05T20:07:49.995067",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "049d38fffd0947189479fcfb288acbe9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FileUploadModel",
      "state": {
       "_counter": 0,
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FileUploadModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "FileUploadView",
       "accept": "",
       "button_style": "",
       "data": [],
       "description": "Upload",
       "description_tooltip": null,
       "disabled": false,
       "error": "",
       "icon": "upload",
       "layout": "IPY_MODEL_e309697a25eb4aa6beff56738f1a5802",
       "metadata": [],
       "multiple": false,
       "style": "IPY_MODEL_d68d1567b4c34f8c8c73374381b50e78"
      }
     },
     "068e88ad7dd04794a734dff5bd0bb4eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "4cb0fcc88674484987d538c002e0add3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4d12e5b1d8624a06a09882ef9270a6d4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6c4b2582b3c941a5b9333f474c61dfa4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "82b9d62d087d4472acf4bb2cefea6136": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "Predict",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_6c4b2582b3c941a5b9333f474c61dfa4",
       "style": "IPY_MODEL_068e88ad7dd04794a734dff5bd0bb4eb",
       "tooltip": ""
      }
     },
     "d68d1567b4c34f8c8c73374381b50e78": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "e14ed34045f8430082a1b37f60497d27": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_4cb0fcc88674484987d538c002e0add3",
       "msg_id": "",
       "outputs": []
      }
     },
     "e309697a25eb4aa6beff56738f1a5802": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eb614248e0bb48d6a6c972073893985a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_82b9d62d087d4472acf4bb2cefea6136",
        "IPY_MODEL_e14ed34045f8430082a1b37f60497d27"
       ],
       "layout": "IPY_MODEL_4d12e5b1d8624a06a09882ef9270a6d4"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
